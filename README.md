**ФИО:** Хайдукова Мария Игоревна  
**Группа:** БИВТ-23-СП-3

В репозитории собраны лабораторные работы по Python для дисциплины: введение в прикладной ИИ.

## Лабораторная работа №1: базовые конструкции Python

**Описание:**  
Создала переменные разных типов, написала функции для математических и прикладных задач, реализовала классы с методами. Проверила работу с помощью `assert` – все тесты прошли успешно.

**Результат:**  
Все задания выполнены корректно, тесты проходят.

## Лабораторная работа №2: анализ данных и EDA

**Описание:**    
Провела полный анализ датасета `"Students Adaptability Level in Online Education"`. Изучила распределения переменных, проверила данные на пропуски и аномалии, проанализировала взаимосвязи признаков с целевой переменной. Построила гистограммы, тепловые карты и другие визуализации для исследования данных.

**Результат:**  
Выявлены ключевые предикторы уровня адаптивности студентов к онлайн-образованию. Обнаружен дисбаланс классов в целевой переменной. Определены признаки с сильной и слабой взаимосвязью с целевой переменной. Все этапы EDA выполнены в соответствии с требованиями задания.

## Лабораторная работа №3: классическое машинное обучение

**Описание:**    
Провела сравнительный анализ различных алгоритмов машинного обучения для задачи многоклассовой классификации уровня адаптивности студентов. Реализовала полный пайплайн: предобработка данных (кодирование категориальных признаков, масштабирование, работа с пропусками), разделение на train/test выборки, обучение и валидация моделей.

**Исследованные модели:**  
- Линейная модель (Logistic Regression)
- Деревья решений (Decision Tree) с разной глубиной
- Метод k-ближайших соседей (KNN) с различным k
- Случайный лес (Random Forest)

**Результат:**  
Проведено сравнение 9 моделей по метрикам Accuracy, F1-score и ROC-AUC. Random Forest показал наилучшее качество с ROC-AUC = 0.98 на тестовой выборке. Дерево с глубиной 10 продемонстрировало оптимальный баланс между качеством и переобучением (разница train/test accuracy всего 1.3%). Построены ROC-AUC и Precision-Recall кривые для анализа рабочих характеристик моделей.

## Лабораторная работа №4: нейронные сети на PyTorch

**Описание:**   
Реализовала нейронные сети для решения той же задачи классификации с использованием фреймворка PyTorch. Создала кастомный Dataset и DataLoader для эффективной работы с данными. Исследовала различные архитектуры нейросетей и оптимизаторы.

**Архитектуры моделей:**  
- Однослойная нейросеть с оптимизатором SGD
- Двухслойная сеть со скрытым слоем (32 нейрона) и оптимизатором Adam
- Четырехслойная сеть (64-32-16-3) с оптимизатором Adam

**Результат:**  
Наиболее сложная модель (4 слоя) достигла accuracy 79.8% на тестовых данных. Построены learning curves для анализа сходимости: все модели успешно обучаются, наблюдается умеренное переобучение у более сложных архитектур. Реализован полный цикл работы с PyTorch: от создания датасета до обучения и валидации моделей.

## Лабораторная работа №5: компьютерное зрение и Transfer Learning

**Описание:**   
Решила задачу многоклассовой классификации изображений игральных карт (53 класса) с использованием методов компьютерного зрения. Применила transfer learning на предобученной модели ResNet18. Настроила пайплайн аугментаций данных для улучшения обобщающей способности модели.

**Ключевые этапы:**  
- Загрузка и анализ датасета (8,154 изображения, 53 класса)
- EDA: анализ распределения классов, визуализация примеров
- Настройка аугментаций: RandomRotation, ColorJitter, RandomPerspective
- Transfer learning с fine-tuning последних слоев ResNet18
- Обучение с использованием AdamW оптимизатора

**Результат:**  
Модель достигла accuracy 86.8% на валидационной выборке с F1-score 0.86. Проведен детальный анализ ошибок через confusion matrix: выявлена частая путаница между валетами и королями одной масти. Построены ROC-кривые для первых 5 классов (AUC > 0.95). Модель демонстрирует хорошую обобщающую способность без значительного переобучения.